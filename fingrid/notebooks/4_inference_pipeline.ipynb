{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70839253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import hopsworks\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "\n",
    "today = datetime.datetime.now()\n",
    "print(f\"Inference date: {today}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e82d7a",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c470146a",
   "metadata": {},
   "source": [
    "# <span style=\"font-width:bold; font-size: 3rem; color:#333;\">Batch Inference Pipeline</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834b364d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/fingrid from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('fingrid',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH`\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env (if running locally)\n",
    "# In GitHub Actions, environment variables are already set\n",
    "if os.path.exists(f\"{root_dir}/.env\"):\n",
    "    from mlfs import config\n",
    "    settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")\n",
    "else:\n",
    "    # GitHub Actions environment - settings not needed\n",
    "    settings = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b379ecd0",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\"> Connect to Hopsworks Feature Store </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd5f9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store()\n",
    "mr = project.get_model_registry()\n",
    "\n",
    "secrets = hopsworks.get_secrets_api()\n",
    "location_str = secrets.get_secret(\"FINGRID_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country = location['country']\n",
    "city = location['city']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378288b4",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">Download the model from Model Registry</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32626eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all 4 models from fingrid/energy_model directory\n",
    "models_dict = {}\n",
    "\n",
    "# Define model paths (all in fingrid/energy_model)\n",
    "model_dir = f\"{root_dir}/fingrid/energy_model\"\n",
    "\n",
    "model_files = {\n",
    "    'baseline': f\"{model_dir}/energy_consumption_predictor.pkl\",\n",
    "    '1_day': f\"{model_dir}/energy_consumption_predictor_1_day_lag.pkl\",\n",
    "    '2_day': f\"{model_dir}/energy_consumption_predictor_2_day_lag.pkl\",\n",
    "    '3_day': f\"{model_dir}/energy_consumption_predictor_3_day_lag.pkl\",\n",
    "}\n",
    "\n",
    "# Load all models\n",
    "for model_name, model_path in model_files.items():\n",
    "    if os.path.exists(model_path):\n",
    "        models_dict[model_name] = joblib.load(model_path)\n",
    "        print(f\"âœ“ {model_name} model loaded\")\n",
    "    else:\n",
    "        print(f\"âœ— {model_name} model not found at: {model_path}\")\n",
    "\n",
    "print(f\"\\nTotal models loaded: {len(models_dict)}\")\n",
    "print(f\"Models: {list(models_dict.keys())}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ff3451",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">Get Weather Forecast Features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c0413f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weather forecast data and historical energy data for lag features\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_finland',\n",
    "    version=1,\n",
    ")\n",
    "energy_fg = fs.get_feature_group(\n",
    "    name='energy_consumption',\n",
    "    version=1,\n",
    ")\n",
    "\n",
    "# Get 7 days of FUTURE forecast starting from today\n",
    "batch_data = weather_fg.read()\n",
    "\n",
    "# Ensure timezone-naive for filtering\n",
    "if batch_data['date'].dt.tz is not None:\n",
    "    batch_data['date'] = batch_data['date'].dt.tz_localize(None)\n",
    "\n",
    "# Filter for next 7 days\n",
    "start_date = pd.Timestamp(today.date())\n",
    "end_date = start_date + pd.Timedelta(days=7)\n",
    "batch_data = batch_data[\n",
    "    (batch_data['date'] >= start_date) & (batch_data['date'] < end_date)\n",
    "].copy()\n",
    "\n",
    "print(f\"Weather forecast data: {len(batch_data)} rows from {start_date.date()} to {end_date.date()}\")\n",
    "print(f\"Date range: {batch_data['date'].min()} to {batch_data['date'].max()}\")\n",
    "print(f\"Unique days: {batch_data['date'].dt.date.nunique()}\")\n",
    "\n",
    "# Get historical energy data to calculate lags (last 72+ hours)\n",
    "energy_data = energy_fg.read()\n",
    "energy_data['date'] = pd.to_datetime(energy_data['date'])\n",
    "if energy_data['date'].dt.tz is not None:\n",
    "    energy_data['date'] = energy_data['date'].dt.tz_localize(None)\n",
    "\n",
    "# Get data from 72 hours before today\n",
    "lookback_start = start_date - pd.Timedelta(hours=72)\n",
    "energy_lookback = energy_data[\n",
    "    (energy_data['date'] >= lookback_start) & (energy_data['date'] < start_date)\n",
    "].copy().sort_values('date')\n",
    "\n",
    "print(f\"\\nHistorical energy data for lag calculation: {len(energy_lookback)} rows\")\n",
    "print(f\"Date range: {energy_lookback['date'].min()} to {energy_lookback['date'].max()}\")\n",
    "\n",
    "batch_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57cb098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnose weather forecast data\n",
    "print(f\"Total rows fetched: {len(batch_data)}\")\n",
    "print(f\"Date range in weather data: {batch_data['date'].min()} to {batch_data['date'].max()}\")\n",
    "print(f\"Unique dates: {batch_data['date'].dt.date.nunique()}\")\n",
    "\n",
    "print(f\"\\nRows per date:\")\n",
    "print(batch_data['date'].dt.date.value_counts().sort_index())\n",
    "\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(batch_data[['date', 'temperature_2m', 'wind_speed_10m']].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d1930a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">Add Temporal Features</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b95c9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temporal features to forecast data\n",
    "batch_data['year'] = batch_data['date'].dt.year\n",
    "batch_data['month'] = batch_data['date'].dt.month\n",
    "batch_data['day'] = batch_data['date'].dt.day\n",
    "batch_data['hour'] = batch_data['date'].dt.hour\n",
    "batch_data['day_of_week'] = batch_data['date'].dt.dayofweek\n",
    "batch_data['is_weekend'] = (batch_data['day_of_week'] >= 5).astype(int)\n",
    "batch_data['week_of_year'] = batch_data['date'].dt.isocalendar().week\n",
    "\n",
    "print(\"Features created:\")\n",
    "print(batch_data.columns.tolist())\n",
    "batch_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e6cb5",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">Add Cyclic Features</span>\n",
    "\n",
    "Convert temporal features to cyclic encoding (matching training pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da96c2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features from recent historical data\n",
    "# We need to combine historical data with forecast data to have continuous consumption history\n",
    "\n",
    "# Combine historical and forecast periods\n",
    "combined_data = pd.concat([energy_lookback[['date', 'consumption_mw']], \n",
    "                          batch_data[['date']].copy()], ignore_index=True).sort_values('date')\n",
    "\n",
    "# Create lag features (24h, 48h, 72h) on the combined data\n",
    "lag_hours = [24, 48, 72]\n",
    "for lag in lag_hours:\n",
    "    combined_data[f'consumption_lag_{lag}h'] = combined_data.groupby(combined_data['date'].dt.date)['consumption_mw'].shift(lag).fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Extract lag features for the forecast period\n",
    "batch_data = batch_data.merge(\n",
    "    combined_data[['date', 'consumption_lag_24h', 'consumption_lag_48h', 'consumption_lag_72h']],\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Forward/backward fill any remaining NaNs\n",
    "batch_data[['consumption_lag_24h', 'consumption_lag_48h', 'consumption_lag_72h']] = batch_data[['consumption_lag_24h', 'consumption_lag_48h', 'consumption_lag_72h']].fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "print(\"Lag features created for forecast period:\")\n",
    "print(batch_data[['date', 'consumption_lag_24h', 'consumption_lag_48h', 'consumption_lag_72h']].head(10))\n",
    "batch_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d667e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">Making the predictions</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d80804a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with all 4 models\n",
    "# Define feature requirements for each model\n",
    "model_configs = {\n",
    "    'baseline': {\n",
    "        'features': ['year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend', 'week_of_year',\n",
    "                    'temperature_2m', 'precipitation', 'cloud_cover', \n",
    "                    'wind_speed_10m', 'wind_speed_100m', 'wind_direction_10m', \n",
    "                    'surface_pressure', 'shortwave_radiation'],\n",
    "        'description': 'No lag features'\n",
    "    },\n",
    "    '1_day': {\n",
    "        'features': ['year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend', 'week_of_year',\n",
    "                    'temperature_2m', 'precipitation', 'cloud_cover', \n",
    "                    'wind_speed_10m', 'wind_speed_100m', 'wind_direction_10m', \n",
    "                    'surface_pressure', 'shortwave_radiation',\n",
    "                    'consumption_lag_24h'],\n",
    "        'description': '1-day (24h) lag feature'\n",
    "    },\n",
    "    '2_day': {\n",
    "        'features': ['year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend', 'week_of_year',\n",
    "                    'temperature_2m', 'precipitation', 'cloud_cover', \n",
    "                    'wind_speed_10m', 'wind_speed_100m', 'wind_direction_10m', \n",
    "                    'surface_pressure', 'shortwave_radiation',\n",
    "                    'consumption_lag_48h'],\n",
    "        'description': '2-day (48h) lag feature'\n",
    "    },\n",
    "    '3_day': {\n",
    "        'features': ['year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend', 'week_of_year',\n",
    "                    'temperature_2m', 'precipitation', 'cloud_cover', \n",
    "                    'wind_speed_10m', 'wind_speed_100m', 'wind_direction_10m', \n",
    "                    'surface_pressure', 'shortwave_radiation',\n",
    "                    'consumption_lag_72h'],\n",
    "        'description': '3-day (72h) lag feature'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Make predictions with each model\n",
    "predictions_all = {}\n",
    "\n",
    "for model_name, config in model_configs.items():\n",
    "    if model_name in models_dict:\n",
    "        # Prepare features\n",
    "        X_pred = batch_data[config['features']].copy()\n",
    "        \n",
    "        # Make predictions\n",
    "        predictions_all[model_name] = models_dict[model_name].predict(X_pred)\n",
    "        batch_data[f'predicted_{model_name}'] = predictions_all[model_name]\n",
    "        \n",
    "        print(f\"âœ“ Predictions made with {model_name} model ({config['description']})\")\n",
    "        print(f\"  Min: {predictions_all[model_name].min():.0f} MW, Max: {predictions_all[model_name].max():.0f} MW\")\n",
    "    else:\n",
    "        print(f\"âœ— {model_name} model not available\")\n",
    "\n",
    "print(\"\\nPredictions summary:\")\n",
    "print(batch_data[['date', 'predicted_baseline', 'predicted_1_day', 'predicted_2_day', 'predicted_3_day']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29848c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0045c0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample to daily averages for cleaner visualization\n",
    "batch_data['date'] = pd.to_datetime(batch_data['date'])\n",
    "# Select only numeric prediction columns for resampling\n",
    "prediction_cols = ['predicted_baseline', 'predicted_1_day', 'predicted_2_day', 'predicted_3_day']\n",
    "df_daily = batch_data[['date'] + prediction_cols].set_index('date').resample('D').mean().reset_index()\n",
    "\n",
    "# Plot forecast with all 4 models\n",
    "plt.figure(figsize=(16, 7))\n",
    "\n",
    "# Define colors and linestyles for each model\n",
    "colors = {\n",
    "    'baseline': '#000000',      # Black\n",
    "    '1_day': '#1f77b4',         # Blue\n",
    "    '2_day': '#ff7f0e',         # Orange\n",
    "    '3_day': '#2ca02c'          # Green\n",
    "}\n",
    "\n",
    "linestyles = {\n",
    "    'baseline': '-',            # Solid\n",
    "    '1_day': '--',             # Dashed\n",
    "    '2_day': '-.',             # Dash-dot\n",
    "    '3_day': ':'               # Dotted\n",
    "}\n",
    "\n",
    "labels = {\n",
    "    'baseline': 'Baseline (No Lags)',\n",
    "    '1_day': 'Predicted (1-Day Lag)',\n",
    "    '2_day': 'Predicted (2-Day Lag)',\n",
    "    '3_day': 'Predicted (3-Day Lag)'\n",
    "}\n",
    "\n",
    "# Plot each model's predictions\n",
    "for model_name in ['baseline', '1_day', '2_day', '3_day']:\n",
    "    if f'predicted_{model_name}' in df_daily.columns:\n",
    "        plt.plot(df_daily['date'], df_daily[f'predicted_{model_name}'], \n",
    "                linewidth=2, alpha=0.7, label=labels[model_name],\n",
    "                color=colors[model_name], linestyle=linestyles[model_name])\n",
    "\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Consumption (MW)', fontsize=12)\n",
    "plt.title('Finland Energy Consumption Forecast - All 4 Models (Daily Average)', fontsize=14)\n",
    "plt.legend(fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "pred_file_path = f\"{root_dir}/docs/fingrid/assets/img/energy_forecast_all_models.png\"\n",
    "os.makedirs(os.path.dirname(pred_file_path), exist_ok=True)\n",
    "plt.savefig(pred_file_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Forecast with all 4 models saved to: {pred_file_path}\")\n",
    "print(f\"Forecasting {len(df_daily)} days\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b3ee7",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">ðŸ¤– Saving the predictions (for monitoring) to a Feature Group</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409813f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata for monitoring\n",
    "batch_data['country'] = country\n",
    "batch_data['days_before_forecast_day'] = (batch_data['date'] - pd.Timestamp(today.date())).dt.days\n",
    "batch_data = batch_data.sort_values(by=['date'])\n",
    "batch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8837db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get or create monitoring feature group (version 3 with all 4 models)\n",
    "monitor_fg = fs.get_or_create_feature_group(\n",
    "    name='energy_predictions',\n",
    "    description='Energy consumption prediction monitoring - all 4 models',\n",
    "    version=3,\n",
    "    primary_key=['country','date','days_before_forecast_day'],\n",
    "    event_time=\"date\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4145a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep predictions from all 4 models for monitoring\n",
    "monitoring_data = batch_data[[\n",
    "    'date', 'country', 'days_before_forecast_day', \n",
    "    'predicted_baseline', 'predicted_1_day', 'predicted_2_day', 'predicted_3_day'\n",
    "]].copy()\n",
    "\n",
    "monitor_fg.insert(monitoring_data, wait=True)\n",
    "print(f\"Inserted {len(monitoring_data)} predictions from all 4 models into monitoring feature group\")\n",
    "print(f\"Columns saved: {[col for col in monitoring_data.columns if 'predicted' in col]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0874d2",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">Create Hindcast - Compare Predictions vs Actual</span>\n",
    "\n",
    "This shows how well the 1-day-ahead predictions matched actual consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaefb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get historical predictions made 1 day before\n",
    "current_week_start = pd.Timestamp(today.date()) - pd.Timedelta(days=7)\n",
    "\n",
    "monitoring_df = monitor_fg.filter(monitor_fg.days_before_forecast_day == 1).read()\n",
    "\n",
    "# Filter to current week only (last 7 days)\n",
    "monitoring_df['date'] = pd.to_datetime(monitoring_df['date'])\n",
    "\n",
    "# Ensure timezone-naive for filtering\n",
    "if monitoring_df['date'].dt.tz is not None:\n",
    "    monitoring_df['date'] = monitoring_df['date'].dt.tz_localize(None)\n",
    "\n",
    "monitoring_df = monitoring_df[monitoring_df['date'] >= current_week_start]\n",
    "\n",
    "print(f\"Historical predictions (current week): {len(monitoring_df)} rows\")\n",
    "print(f\"Date range: {monitoring_df['date'].min().date() if len(monitoring_df) > 0 else 'None'} to {monitoring_df['date'].max().date() if len(monitoring_df) > 0 else 'None'}\")\n",
    "monitoring_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a1ba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual energy consumption data - filter to current week\n",
    "energy_fg = fs.get_feature_group(name='energy_consumption', version=1)\n",
    "energy_df = energy_fg.read()\n",
    "energy_df['date'] = pd.to_datetime(energy_df['date'])\n",
    "\n",
    "# Ensure timezone-naive for filtering\n",
    "if energy_df['date'].dt.tz is not None:\n",
    "    energy_df['date'] = energy_df['date'].dt.tz_localize(None)\n",
    "\n",
    "energy_df = energy_df[energy_df['date'] >= current_week_start]\n",
    "\n",
    "print(f\"Actual consumption data (current week): {len(energy_df)} rows\")\n",
    "print(f\"Date range: {energy_df['date'].min().date() if len(energy_df) > 0 else 'None'} to {energy_df['date'].max().date() if len(energy_df) > 0 else 'None'}\")\n",
    "energy_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3604451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample actual consumption to daily averages\n",
    "energy_df['date_only'] = energy_df['date'].dt.date\n",
    "energy_daily = energy_df.groupby('date_only')['consumption_mw'].mean().reset_index()\n",
    "energy_daily.columns = ['date', 'actual_consumption']\n",
    "energy_daily['date'] = pd.to_datetime(energy_daily['date'])\n",
    "\n",
    "# Resample predictions to daily averages - only 1-day lag predictions\n",
    "if len(monitoring_df) > 0:\n",
    "    monitoring_df['date_only'] = monitoring_df['date'].dt.date\n",
    "    \n",
    "    # Aggregate 1-day model predictions to daily average\n",
    "    preds_daily = monitoring_df.groupby('date_only').agg({\n",
    "        'predicted_1_day': 'mean'\n",
    "    }).reset_index()\n",
    "    preds_daily.columns = ['date', 'predicted_1_day']\n",
    "    preds_daily['date'] = pd.to_datetime(preds_daily['date'])\n",
    "    \n",
    "    # Merge predictions with actuals\n",
    "    hindcast_df = pd.merge(preds_daily, energy_daily, on='date', how='inner')\n",
    "    hindcast_df = hindcast_df.sort_values(by=['date'])\n",
    "    \n",
    "    print(f\"Hindcast data points (current week): {len(hindcast_df)}\")\n",
    "    print(f\"Date range: {hindcast_df['date'].min().date()} to {hindcast_df['date'].max().date()}\")\n",
    "else:\n",
    "    hindcast_df = pd.DataFrame()\n",
    "    print(\"No historical predictions yet for hindcast\")\n",
    "\n",
    "hindcast_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142c1d4c",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\">Plot Hindcast</span>\n",
    "\n",
    "__This graph will be empty initially - this is normal.__\n",
    "\n",
    "After a few days of predictions and observations, you will see data points comparing predictions vs actual consumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ed6530",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "if len(hindcast_df) > 0:\n",
    "    # Plot actual consumption\n",
    "    plt.plot(hindcast_df['date'], hindcast_df['actual_consumption'], \n",
    "             linewidth=2.5, alpha=0.8, label='Actual Consumption', color='black', marker='o')\n",
    "    \n",
    "    # Plot 1-day ahead prediction\n",
    "    plt.plot(hindcast_df['date'], hindcast_df['predicted_1_day'], \n",
    "             linewidth=2, alpha=0.7, label='1-Day Ahead Prediction', \n",
    "             color='#1f77b4', linestyle='--', marker='s')\n",
    "else:\n",
    "    plt.text(0.5, 0.5, 'Waiting for historical data...', \n",
    "             ha='center', va='center', transform=plt.gca().transAxes, fontsize=14)\n",
    "\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Consumption (MW)', fontsize=12)\n",
    "plt.title('Finland Energy Consumption Hindcast - Current Week (1-Day Ahead)', fontsize=14)\n",
    "plt.legend(fontsize=10, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save plot\n",
    "hindcast_file_path = f\"{root_dir}/docs/fingrid/assets/img/energy_hindcast_all_models.png\"\n",
    "os.makedirs(os.path.dirname(hindcast_file_path), exist_ok=True)\n",
    "plt.savefig(hindcast_file_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Hindcast saved to: {hindcast_file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4c9f30",
   "metadata": {},
   "source": [
    "### Upload the prediction and hindcast dashboards (png files) to Hopsworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_api = project.get_dataset_api()\n",
    "str_today = today.strftime(\"%Y-%m-%d\")\n",
    "if dataset_api.exists(\"Resources/fingrid\") == False:\n",
    "    dataset_api.mkdir(\"Resources/fingrid\")\n",
    "dataset_api.upload(pred_file_path, f\"Resources/fingrid/{country}_{city}_{str_today}\", overwrite=True)\n",
    "dataset_api.upload(hindcast_file_path, f\"Resources/fingrid/{country}_{city}_{str_today}\", overwrite=True)\n",
    "\n",
    "proj_url = project.get_url()\n",
    "print(f\"See images in Hopsworks here: {proj_url}/settings/fb/path/Resources/fingrid\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfs-fingrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
