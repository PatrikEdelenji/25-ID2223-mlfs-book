{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6a9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Root dir: c:\\Users\\patri\\VScodeProjects\\25-ID2223-mlfs-book\n",
      "Added the following directory to the PYTHONPATH: c:\\Users\\patri\\VScodeProjects\\25-ID2223-mlfs-book\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/fingrid from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('fingrid',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51319b",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill for Fingrid Energy Consumption Data</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77395dcc",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2488b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define today's date\n",
    "today = datetime.today()\n",
    "\n",
    "# Get API keys from settings\n",
    "FINGRID_API_KEY = settings.FINGRID_KEY\n",
    "if FINGRID_API_KEY is None:\n",
    "    print(\"Warning: FINGRID_KEY not found in .env file. You'll need it to fetch energy data.\")\n",
    "else:\n",
    "    # Convert SecretStr to plain string for use with requests library\n",
    "    FINGRID_API_KEY = FINGRID_API_KEY.get_secret_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e3ecc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> STEP 1: Get your Fingrid API Token and Store it in .env file</span>\n",
    "\n",
    "You need to get your Fingrid API key from https://data.fingrid.fi/en/\n",
    "\n",
    "Once you have your API key, save it to the .env file in the root directory of your project:\n",
    "\n",
    " * mv .env.example .env\n",
    " * edit .env\n",
    "\n",
    "In the .env file, add or update:\n",
    "\n",
    "`FINGRID_KEY=\"put your Fingrid API KEY value in this string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2a0fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 20:41:52,160 INFO: Initializing external client\n",
      "2026-01-01 20:41:52,161 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2026-01-01 20:41:54,289 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1286359\n"
     ]
    }
   ],
   "source": [
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe50e9",
   "metadata": {},
   "source": [
    "## Hopsworks API Key\n",
    "\n",
    "You need to have registered an account on app.hopsworks.ai.\n",
    "\n",
    "Save the HOPSWORKS_API_KEY to the .env file in the root directory of your project:\n",
    "\n",
    " * mv .env.example .env\n",
    " * edit .env\n",
    "\n",
    "In the .env file, update HOPSWORKS_API_KEY:\n",
    "\n",
    "`HOPSWORKS_API_KEY=\"put API KEY value in this string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12349995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country: Finland\n",
      "Weather measurement location: Helsinki (60.1699, 24.9384)\n",
      "Backfill period: 2024-01-02 to 2026-01-01\n",
      "Local data directory: c:\\Users\\patri\\VScodeProjects\\25-ID2223-mlfs-book/data\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "FINGRID_BASE_URL = \"https://data.fingrid.fi/api/datasets\"\n",
    "DATASET_ID = \"193\"  # Electricity consumption in Finland (MW)\n",
    "\n",
    "# Weather location (Helsinki coordinates as representative measurement point for Finland)\n",
    "COUNTRY = \"Finland\"\n",
    "CITY = \"Helsinki\"\n",
    "LATITUDE = 60.1699\n",
    "LONGITUDE = 24.9384\n",
    "\n",
    "# Backfill configuration - how many days of historical data to download\n",
    "BACKFILL_DAYS = 730  # 2 years of data for complete seasonal coverage\n",
    "end_date = today\n",
    "start_date = end_date - timedelta(days=BACKFILL_DAYS)\n",
    "\n",
    "# Local storage configuration\n",
    "DATA_DIR = f\"{root_dir}/data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Country: {COUNTRY}\")\n",
    "print(f\"Weather measurement location: {CITY} ({LATITUDE}, {LONGITUDE})\")\n",
    "print(f\"Backfill period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Local data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e03e65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 2: Download Historical Energy Consumption Data from Fingrid</span>\n",
    "\n",
    "We will fetch historical electricity consumption data from Fingrid's open data API.\n",
    "The data is measured every 3 hours and represents Finland's nationwide electricity consumption in megawatts (MW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5a5adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data fetching functions defined\n"
     ]
    }
   ],
   "source": [
    "def fetch_fingrid_data(dataset_id, start_date, end_date, api_key):\n",
    "    \"\"\"\n",
    "    Fetch historical data from Fingrid API.\n",
    "    \n",
    "    Args:\n",
    "        dataset_id: Fingrid dataset ID\n",
    "        start_date: Start date (datetime)\n",
    "        end_date: End date (datetime)\n",
    "        api_key: Fingrid API key\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with timestamp and value columns\n",
    "    \"\"\"\n",
    "    url = f\"{FINGRID_BASE_URL}/{dataset_id}/data\"\n",
    "    \n",
    "    params = {\n",
    "        \"startTime\": start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        \"endTime\": end_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        \"format\": \"json\",\n",
    "        \"pageSize\": 20000  # Max records per request\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching energy data from {params['startTime']} to {params['endTime']}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'data' in data:\n",
    "            df = pd.DataFrame(data['data'])\n",
    "            print(f\"Fetched {len(df)} records from Fingrid API\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Warning: No 'data' field in response: {list(data.keys())}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_weather_data(latitude, longitude, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical weather data from Open-Meteo API.\n",
    "    Free API - no key required!\n",
    "    \n",
    "    Args:\n",
    "        latitude: Location latitude\n",
    "        longitude: Location longitude\n",
    "        start_date: Start date (datetime)\n",
    "        end_date: End date (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with weather variables\n",
    "    \"\"\"\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    \n",
    "    # Format dates for API\n",
    "    start_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Weather variables optimized for energy forecasting\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": start_str,\n",
    "        \"end_date\": end_str,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"cloud_cover\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_speed_100m\",\n",
    "            \"wind_direction_10m\",\n",
    "            \"surface_pressure\",\n",
    "            \"shortwave_radiation\"\n",
    "        ],\n",
    "        \"timezone\": \"Europe/Helsinki\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching weather data from {start_str} to {end_str}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'hourly' in data:\n",
    "            # Convert to DataFrame\n",
    "            hourly = data['hourly']\n",
    "            df = pd.DataFrame({\n",
    "                'date': pd.to_datetime(hourly['time']),\n",
    "                'temperature_2m': hourly['temperature_2m'],\n",
    "                'precipitation': hourly['precipitation'],\n",
    "                'cloud_cover': hourly['cloud_cover'],\n",
    "                'wind_speed_10m': hourly['wind_speed_10m'],\n",
    "                'wind_speed_100m': hourly['wind_speed_100m'],\n",
    "                'wind_direction_10m': hourly['wind_direction_10m'],\n",
    "                'surface_pressure': hourly['surface_pressure'],\n",
    "                'shortwave_radiation': hourly['shortwave_radiation']\n",
    "            })\n",
    "            \n",
    "            print(f\"Fetched {len(df)} hourly weather records\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Warning: No 'hourly' field in response: {list(data.keys())}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"Data fetching functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2541a0",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Fetch Energy Data from Fingrid API</span>\n",
    "\n",
    "We fetch data in chunks to respect API rate limits and avoid timeouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ad7abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching energy data from 2024-01-02T20:41:52Z to 2024-01-09T20:41:52Z...\n",
      "Fetched 3360 records from Fingrid API\n",
      "Fetching energy data from 2024-01-09T20:41:52Z to 2024-01-16T20:41:52Z...\n",
      "Fetched 6420 records from Fingrid API\n",
      "Fetching energy data from 2024-01-16T20:41:52Z to 2024-01-23T20:41:52Z...\n",
      "Fetched 6678 records from Fingrid API\n",
      "Fetching energy data from 2024-01-23T20:41:52Z to 2024-01-30T20:41:52Z...\n",
      "Fetched 6718 records from Fingrid API\n",
      "Fetching energy data from 2024-01-30T20:41:52Z to 2024-02-06T20:41:52Z...\n",
      "Fetched 6712 records from Fingrid API\n",
      "Fetching energy data from 2024-02-06T20:41:52Z to 2024-02-13T20:41:52Z...\n",
      "Fetched 6716 records from Fingrid API\n",
      "Fetching energy data from 2024-02-13T20:41:52Z to 2024-02-20T20:41:52Z...\n",
      "Fetched 6664 records from Fingrid API\n",
      "Fetching energy data from 2024-02-20T20:41:52Z to 2024-02-27T20:41:52Z...\n",
      "Fetched 6716 records from Fingrid API\n",
      "Fetching energy data from 2024-02-27T20:41:52Z to 2024-03-05T20:41:52Z...\n",
      "Fetched 6553 records from Fingrid API\n",
      "Fetching energy data from 2024-03-05T20:41:52Z to 2024-03-12T20:41:52Z...\n",
      "Fetched 3286 records from Fingrid API\n",
      "Fetching energy data from 2024-03-12T20:41:52Z to 2024-03-19T20:41:52Z...\n",
      "Fetched 3427 records from Fingrid API\n",
      "Fetching energy data from 2024-03-19T20:41:52Z to 2024-03-26T20:41:52Z...\n",
      "Fetched 4704 records from Fingrid API\n",
      "Fetching energy data from 2024-03-26T20:41:52Z to 2024-04-02T20:41:52Z...\n",
      "Fetched 4704 records from Fingrid API\n",
      "Fetching energy data from 2024-04-02T20:41:52Z to 2024-04-09T20:41:52Z...\n",
      "Fetched 4704 records from Fingrid API\n",
      "Fetching energy data from 2024-04-09T20:41:52Z to 2024-04-16T20:41:52Z...\n",
      "Fetched 4809 records from Fingrid API\n",
      "Fetching energy data from 2024-04-16T20:41:52Z to 2024-04-23T20:41:52Z...\n",
      "Fetched 5345 records from Fingrid API\n",
      "Fetching energy data from 2024-04-23T20:41:52Z to 2024-04-30T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-04-30T20:41:52Z to 2024-05-07T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-05-07T20:41:52Z to 2024-05-14T20:41:52Z...\n",
      "Fetched 3337 records from Fingrid API\n",
      "Fetching energy data from 2024-05-14T20:41:52Z to 2024-05-21T20:41:52Z...\n",
      "Fetched 3355 records from Fingrid API\n",
      "Fetching energy data from 2024-05-21T20:41:52Z to 2024-05-28T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-05-28T20:41:52Z to 2024-06-04T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-06-04T20:41:52Z to 2024-06-11T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-06-11T20:41:52Z to 2024-06-18T20:41:52Z...\n",
      "Fetched 3358 records from Fingrid API\n",
      "Fetching energy data from 2024-06-18T20:41:52Z to 2024-06-25T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-06-25T20:41:52Z to 2024-07-02T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-07-02T20:41:52Z to 2024-07-09T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-07-09T20:41:52Z to 2024-07-16T20:41:52Z...\n",
      "Fetched 3033 records from Fingrid API\n",
      "Fetching energy data from 2024-07-16T20:41:52Z to 2024-07-23T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-07-23T20:41:52Z to 2024-07-30T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-07-30T20:41:52Z to 2024-08-06T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-08-06T20:41:52Z to 2024-08-13T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-08-13T20:41:52Z to 2024-08-20T20:41:52Z...\n",
      "Fetched 3356 records from Fingrid API\n",
      "Fetching energy data from 2024-08-20T20:41:52Z to 2024-08-27T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-08-27T20:41:52Z to 2024-09-03T20:41:52Z...\n",
      "Fetched 3358 records from Fingrid API\n",
      "Fetching energy data from 2024-09-03T20:41:52Z to 2024-09-10T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-09-10T20:41:52Z to 2024-09-17T20:41:52Z...\n",
      "Fetched 3335 records from Fingrid API\n",
      "Fetching energy data from 2024-09-17T20:41:52Z to 2024-09-24T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-09-24T20:41:52Z to 2024-10-01T20:41:52Z...\n",
      "Fetched 3358 records from Fingrid API\n",
      "Fetching energy data from 2024-10-01T20:41:52Z to 2024-10-08T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-10-08T20:41:52Z to 2024-10-15T20:41:52Z...\n",
      "Fetched 3302 records from Fingrid API\n",
      "Fetching energy data from 2024-10-15T20:41:52Z to 2024-10-22T20:41:52Z...\n",
      "Fetched 3047 records from Fingrid API\n",
      "Fetching energy data from 2024-10-22T20:41:52Z to 2024-10-29T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2024-10-29T20:41:52Z to 2024-11-05T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-11-05T20:41:52Z to 2024-11-12T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-11-12T20:41:52Z to 2024-11-19T20:41:52Z...\n",
      "Fetched 3355 records from Fingrid API\n",
      "Fetching energy data from 2024-11-19T20:41:52Z to 2024-11-26T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-11-26T20:41:52Z to 2024-12-03T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-12-03T20:41:52Z to 2024-12-10T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-12-10T20:41:52Z to 2024-12-17T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2024-12-17T20:41:52Z to 2024-12-24T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-12-24T20:41:52Z to 2024-12-31T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2024-12-31T20:41:52Z to 2025-01-07T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-01-07T20:41:52Z to 2025-01-14T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-01-14T20:41:52Z to 2025-01-21T20:41:52Z...\n",
      "Fetched 3351 records from Fingrid API\n",
      "Fetching energy data from 2025-01-21T20:41:52Z to 2025-01-28T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-01-28T20:41:52Z to 2025-02-04T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-02-04T20:41:52Z to 2025-02-11T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-02-11T20:41:52Z to 2025-02-18T20:41:52Z...\n",
      "Fetched 3354 records from Fingrid API\n",
      "Fetching energy data from 2025-02-18T20:41:52Z to 2025-02-25T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-02-25T20:41:52Z to 2025-03-04T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-03-04T20:41:52Z to 2025-03-11T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-03-11T20:41:52Z to 2025-03-18T20:41:52Z...\n",
      "Fetched 3356 records from Fingrid API\n",
      "Fetching energy data from 2025-03-18T20:41:52Z to 2025-03-25T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-03-25T20:41:52Z to 2025-04-01T20:41:52Z...\n",
      "Fetched 3358 records from Fingrid API\n",
      "Fetching energy data from 2025-04-01T20:41:52Z to 2025-04-08T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-04-08T20:41:52Z to 2025-04-15T20:41:52Z...\n",
      "Fetched 3340 records from Fingrid API\n",
      "Fetching energy data from 2025-04-15T20:41:52Z to 2025-04-22T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-04-22T20:41:52Z to 2025-04-29T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-04-29T20:41:52Z to 2025-05-06T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-05-06T20:41:52Z to 2025-05-13T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-05-13T20:41:52Z to 2025-05-20T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2025-05-20T20:41:52Z to 2025-05-27T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-05-27T20:41:52Z to 2025-06-03T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-06-03T20:41:52Z to 2025-06-10T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-06-10T20:41:52Z to 2025-06-17T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2025-06-17T20:41:52Z to 2025-06-24T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-06-24T20:41:52Z to 2025-07-01T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-07-01T20:41:52Z to 2025-07-08T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-07-08T20:41:52Z to 2025-07-15T20:41:52Z...\n",
      "Fetched 3240 records from Fingrid API\n",
      "Fetching energy data from 2025-07-15T20:41:52Z to 2025-07-22T20:41:52Z...\n",
      "Fetched 3341 records from Fingrid API\n",
      "Fetching energy data from 2025-07-22T20:41:52Z to 2025-07-29T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-07-29T20:41:52Z to 2025-08-05T20:41:52Z...\n",
      "Fetched 3335 records from Fingrid API\n",
      "Fetching energy data from 2025-08-05T20:41:52Z to 2025-08-12T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-08-12T20:41:52Z to 2025-08-19T20:41:52Z...\n",
      "Fetched 3349 records from Fingrid API\n",
      "Fetching energy data from 2025-08-19T20:41:52Z to 2025-08-26T20:41:52Z...\n",
      "Fetched 3354 records from Fingrid API\n",
      "Fetching energy data from 2025-08-26T20:41:52Z to 2025-09-02T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-09-02T20:41:52Z to 2025-09-09T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-09-09T20:41:52Z to 2025-09-16T20:41:52Z...\n",
      "Fetched 3358 records from Fingrid API\n",
      "Fetching energy data from 2025-09-16T20:41:52Z to 2025-09-23T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-09-23T20:41:52Z to 2025-09-30T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-09-30T20:41:52Z to 2025-10-07T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-10-07T20:41:52Z to 2025-10-14T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-10-14T20:41:52Z to 2025-10-21T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-10-21T20:41:52Z to 2025-10-28T20:41:52Z...\n",
      "Fetched 3339 records from Fingrid API\n",
      "Fetching energy data from 2025-10-28T20:41:52Z to 2025-11-04T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2025-11-04T20:41:52Z to 2025-11-11T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-11-11T20:41:52Z to 2025-11-18T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2025-11-18T20:41:52Z to 2025-11-25T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-11-25T20:41:52Z to 2025-12-02T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-12-02T20:41:52Z to 2025-12-09T20:41:52Z...\n",
      "Fetched 3357 records from Fingrid API\n",
      "Fetching energy data from 2025-12-09T20:41:52Z to 2025-12-16T20:41:52Z...\n",
      "Fetched 3356 records from Fingrid API\n",
      "Fetching energy data from 2025-12-16T20:41:52Z to 2025-12-23T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-12-23T20:41:52Z to 2025-12-30T20:41:52Z...\n",
      "Fetched 3359 records from Fingrid API\n",
      "Fetching energy data from 2025-12-30T20:41:52Z to 2026-01-01T20:41:52Z...\n",
      "Fetched 941 records from Fingrid API\n",
      "\n",
      "Total records fetched: 383044\n"
     ]
    }
   ],
   "source": [
    "# Fetch data in chunks if needed (Fingrid API may have limits)\n",
    "all_data = []\n",
    "current_start = start_date\n",
    "chunk_days = 7  # Fetch 7 days at a time\n",
    "\n",
    "while current_start < end_date:\n",
    "    current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "    \n",
    "    df_chunk = fetch_fingrid_data(\n",
    "        dataset_id=DATASET_ID,\n",
    "        start_date=current_start,\n",
    "        end_date=current_end,\n",
    "        api_key=FINGRID_API_KEY\n",
    "    )\n",
    "    \n",
    "    if not df_chunk.empty:\n",
    "        all_data.append(df_chunk)\n",
    "    \n",
    "    current_start = current_end\n",
    "    \n",
    "    # Add delay to respect rate limits\n",
    "    if current_start < end_date:\n",
    "        time.sleep(2)\n",
    "\n",
    "# Combine all chunks\n",
    "if all_data:\n",
    "    df_raw = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nTotal records fetched: {len(df_raw)}\")\n",
    "    df_raw.head()\n",
    "else:\n",
    "    raise ValueError(\"No data fetched. Check API key and date range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cc48e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 3: Download Historical Weather Data </span>\n",
    "\n",
    "We download historical weather data for Helsinki (representative location for Finland) using the free Open-Meteo API.\n",
    "\n",
    "The weather features we download are optimized for energy forecasting:\n",
    " * `temperature` - impacts heating/cooling demand\n",
    " * `precipitation` - affects hydropower generation\n",
    " * `wind speed` - important for wind power generation\n",
    " * `solar radiation` - affects solar power generation\n",
    " * `cloud cover` - impacts solar generation\n",
    " * `surface pressure` - general weather indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f25efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching weather data from 2024-01-02 to 2026-01-01...\n",
      "Fetched 17544 hourly weather records\n",
      "\n",
      "Total weather records fetched: 17544\n",
      "Date range: 2024-01-02 00:00:00 to 2026-01-01 23:00:00\n"
     ]
    }
   ],
   "source": [
    "# Fetch weather data\n",
    "df_weather_raw = fetch_weather_data(\n",
    "    latitude=LATITUDE,\n",
    "    longitude=LONGITUDE,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date\n",
    ")\n",
    "\n",
    "if not df_weather_raw.empty:\n",
    "    print(f\"\\nTotal weather records fetched: {len(df_weather_raw)}\")\n",
    "    print(f\"Date range: {df_weather_raw['date'].min()} to {df_weather_raw['date'].max()}\")\n",
    "    df_weather_raw.head()\n",
    "else:\n",
    "    raise ValueError(\"No weather data fetched. Check date range and network connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23da6c",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> STEP 4: Process Weather Data </span>\n",
    "\n",
    "We resample the hourly weather data to 3-hour intervals to match the frequency of the energy consumption data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aafec824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather data processed: 5848 records (3-hour intervals)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>cloud_cover</th>\n",
       "      <th>wind_speed_10m</th>\n",
       "      <th>wind_speed_100m</th>\n",
       "      <th>wind_direction_10m</th>\n",
       "      <th>surface_pressure</th>\n",
       "      <th>shortwave_radiation</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-01-02 00:00:00</td>\n",
       "      <td>-15.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>25.233333</td>\n",
       "      <td>38.633333</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>1022.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-01-02 03:00:00</td>\n",
       "      <td>-15.233333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>26.666667</td>\n",
       "      <td>40.900000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1021.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-01-02 06:00:00</td>\n",
       "      <td>-15.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>99.333333</td>\n",
       "      <td>25.966667</td>\n",
       "      <td>39.800000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1021.866667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024-01-02 09:00:00</td>\n",
       "      <td>-15.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>24.033333</td>\n",
       "      <td>38.266667</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1022.500000</td>\n",
       "      <td>8.666667</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024-01-02 12:00:00</td>\n",
       "      <td>-15.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>22.866667</td>\n",
       "      <td>36.400000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1022.433333</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>Finland</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 date  temperature_2m  precipitation  cloud_cover  \\\n",
       "0 2024-01-02 00:00:00      -15.666667            0.0   100.000000   \n",
       "1 2024-01-02 03:00:00      -15.233333            0.0   100.000000   \n",
       "2 2024-01-02 06:00:00      -15.066667            0.0    99.333333   \n",
       "3 2024-01-02 09:00:00      -15.833333            0.0   100.000000   \n",
       "4 2024-01-02 12:00:00      -15.133333            0.0   100.000000   \n",
       "\n",
       "   wind_speed_10m  wind_speed_100m  wind_direction_10m  surface_pressure  \\\n",
       "0       25.233333        38.633333           37.333333       1022.100000   \n",
       "1       26.666667        40.900000           41.000000       1021.900000   \n",
       "2       25.966667        39.800000           42.000000       1021.866667   \n",
       "3       24.033333        38.266667           39.000000       1022.500000   \n",
       "4       22.866667        36.400000           39.000000       1022.433333   \n",
       "\n",
       "   shortwave_radiation  country  \n",
       "0             0.000000  Finland  \n",
       "1             0.000000  Finland  \n",
       "2             0.000000  Finland  \n",
       "3             8.666667  Finland  \n",
       "4            41.000000  Finland  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_weather_data(df):\n",
    "    \"\"\"\n",
    "    Process weather data to match energy consumption frequency.\n",
    "    Resample hourly data to 3-hour intervals to match Fingrid data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Set date as index for resampling\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Resample to 3-hour intervals\n",
    "    df_resampled = df.resample('3H').agg({\n",
    "        'temperature_2m': 'mean',\n",
    "        'precipitation': 'sum',\n",
    "        'cloud_cover': 'mean',\n",
    "        'wind_speed_10m': 'mean',\n",
    "        'wind_speed_100m': 'mean',\n",
    "        'wind_direction_10m': 'mean',\n",
    "        'surface_pressure': 'mean',\n",
    "        'shortwave_radiation': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Reset index to make date a column\n",
    "    df_resampled.reset_index(inplace=True)\n",
    "    \n",
    "    # Add country identifier\n",
    "    df_resampled['country'] = COUNTRY\n",
    "    \n",
    "    # Drop any NaN rows\n",
    "    df_resampled = df_resampled.dropna()\n",
    "    \n",
    "    return df_resampled\n",
    "\n",
    "# Process the weather data\n",
    "df_weather_processed = process_weather_data(df_weather_raw)\n",
    "\n",
    "print(f\"Weather data processed: {len(df_weather_processed)} records (3-hour intervals)\")\n",
    "df_weather_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c4a02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 5: Process Energy Consumption Data </span>\n",
    "\n",
    "We process the raw energy data and add temporal features to help with forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65399117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data processed: 383044 records\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>consumption_mw</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>week_of_year</th>\n",
       "      <th>consumption_lag_1</th>\n",
       "      <th>consumption_lag_2</th>\n",
       "      <th>consumption_lag_8</th>\n",
       "      <th>consumption_rolling_mean_24h</th>\n",
       "      <th>consumption_rolling_std_24h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3359</th>\n",
       "      <td>2024-01-02 20:43:00+00:00</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14400.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3358</th>\n",
       "      <td>2024-01-02 20:46:00+00:00</td>\n",
       "      <td>14366.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14383.000000</td>\n",
       "      <td>24.041631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3357</th>\n",
       "      <td>2024-01-02 20:49:00+00:00</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14366.0</td>\n",
       "      <td>14400.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14365.666667</td>\n",
       "      <td>34.501208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3356</th>\n",
       "      <td>2024-01-02 20:52:00+00:00</td>\n",
       "      <td>14277.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14366.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14343.500000</td>\n",
       "      <td>52.526184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3355</th>\n",
       "      <td>2024-01-02 20:55:00+00:00</td>\n",
       "      <td>14385.0</td>\n",
       "      <td>Finland</td>\n",
       "      <td>2024</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14277.0</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14351.800000</td>\n",
       "      <td>49.129421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date  consumption_mw  country  year  month  day  \\\n",
       "3359 2024-01-02 20:43:00+00:00         14400.0  Finland  2024      1    2   \n",
       "3358 2024-01-02 20:46:00+00:00         14366.0  Finland  2024      1    2   \n",
       "3357 2024-01-02 20:49:00+00:00         14331.0  Finland  2024      1    2   \n",
       "3356 2024-01-02 20:52:00+00:00         14277.0  Finland  2024      1    2   \n",
       "3355 2024-01-02 20:55:00+00:00         14385.0  Finland  2024      1    2   \n",
       "\n",
       "      hour  day_of_week  is_weekend  week_of_year  consumption_lag_1  \\\n",
       "3359    20            1           0             1                NaN   \n",
       "3358    20            1           0             1            14400.0   \n",
       "3357    20            1           0             1            14366.0   \n",
       "3356    20            1           0             1            14331.0   \n",
       "3355    20            1           0             1            14277.0   \n",
       "\n",
       "      consumption_lag_2  consumption_lag_8  consumption_rolling_mean_24h  \\\n",
       "3359                NaN                NaN                  14400.000000   \n",
       "3358                NaN                NaN                  14383.000000   \n",
       "3357            14400.0                NaN                  14365.666667   \n",
       "3356            14366.0                NaN                  14343.500000   \n",
       "3355            14331.0                NaN                  14351.800000   \n",
       "\n",
       "      consumption_rolling_std_24h  \n",
       "3359                          NaN  \n",
       "3358                    24.041631  \n",
       "3357                    34.501208  \n",
       "3356                    52.526184  \n",
       "3355                    49.129421  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_energy_data(df):\n",
    "    \"\"\"\n",
    "    Process and engineer features from raw Fingrid data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Parse timestamp\n",
    "    timestamp_col = 'start_time' if 'start_time' in df.columns else 'startTime'\n",
    "    if timestamp_col not in df.columns:\n",
    "        timestamp_col = df.columns[0]\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[timestamp_col])\n",
    "    \n",
    "    # Get consumption value\n",
    "    value_col = 'value' if 'value' in df.columns else df.columns[1]\n",
    "    df['consumption_mw'] = pd.to_numeric(df[value_col], errors='coerce')\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    df = df.drop_duplicates(subset=['date'])\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Extract temporal features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    \n",
    "    # Create lag features\n",
    "    df['consumption_lag_1'] = df['consumption_mw'].shift(1)\n",
    "    df['consumption_lag_2'] = df['consumption_mw'].shift(2)\n",
    "    df['consumption_lag_8'] = df['consumption_mw'].shift(8)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['consumption_rolling_mean_24h'] = df['consumption_mw'].rolling(window=8, min_periods=1).mean()\n",
    "    df['consumption_rolling_std_24h'] = df['consumption_mw'].rolling(window=8, min_periods=1).std()\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    df = df.dropna(subset=['date', 'consumption_mw'])\n",
    "    \n",
    "    # Add country identifier\n",
    "    df['country'] = COUNTRY\n",
    "    \n",
    "    # Select final columns\n",
    "    feature_columns = [\n",
    "        'date',\n",
    "        'consumption_mw',\n",
    "        'country',\n",
    "        'year',\n",
    "        'month',\n",
    "        'day',\n",
    "        'hour',\n",
    "        'day_of_week',\n",
    "        'is_weekend',\n",
    "        'week_of_year',\n",
    "        'consumption_lag_1',\n",
    "        'consumption_lag_2',\n",
    "        'consumption_lag_8',\n",
    "        'consumption_rolling_mean_24h',\n",
    "        'consumption_rolling_std_24h'\n",
    "    ]\n",
    "    \n",
    "    df = df[feature_columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_processed = process_energy_data(df_raw)\n",
    "\n",
    "print(f\"Data processed: {len(df_processed)} records\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf50bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 6: Define Data Validation Rules </span>\n",
    "\n",
    "We define data validation rules (expectations) to ensure data quality before writing to Hopsworks.\n",
    "This prevents garbage-in, garbage-out scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de466bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"expectation_type\": \"expect_column_min_to_be_between\", \"kwargs\": {\"column\": \"consumption_mw\", \"min_value\": 0.0, \"max_value\": 20000.0, \"strict_min\": true}, \"meta\": {}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "energy_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"energy_expectation_suite\"\n",
    ")\n",
    "\n",
    "energy_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"consumption_mw\",\n",
    "            \"min_value\": 0.0,\n",
    "            \"max_value\": 20000.0,\n",
    "            \"strict_min\": True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "524498d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_reasonable_weather(col, min_val, max_val):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\": col,\n",
    "                \"min_value\": min_val,\n",
    "                \"max_value\": max_val,\n",
    "                \"strict_min\": True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "expect_reasonable_weather(\"temperature_2m\", -50.0, 50.0)\n",
    "expect_reasonable_weather(\"precipitation\", 0.0, 500.0)\n",
    "expect_reasonable_weather(\"wind_speed_10m\", 0.0, 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f036a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 7: Save Processed Data Locally </span>\n",
    "\n",
    "Before uploading to Hopsworks, save the processed dataframes as CSV files in the data directory for backup and offline analysis.\n",
    "\n",
    "The files will be saved as:\n",
    " * `energy_consumption_finland.csv` - Energy consumption with features (2 years)\n",
    " * `weather_finland_historical.csv` - Historical weather data (2 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a828e718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Saved energy data to: c:\\Users\\patri\\VScodeProjects\\25-ID2223-mlfs-book/data/energy_consumption_finland.csv\n",
      "  - 383044 records from 2024-01-02 20:43:00+00:00 to 2026-01-01 19:42:00+00:00\n",
      " Saved weather data to: c:\\Users\\patri\\VScodeProjects\\25-ID2223-mlfs-book/data/weather_finland_historical.csv\n",
      "  - 5848 records from 2024-01-02 00:00:00 to 2026-01-01 21:00:00\n",
      "\n",
      " All data saved successfully in: c:\\Users\\patri\\VScodeProjects\\25-ID2223-mlfs-book/data\n"
     ]
    }
   ],
   "source": [
    "# Save processed data to CSV files in the data directory\n",
    "# Using unique names to avoid conflicts with other project data\n",
    "energy_file = f\"{DATA_DIR}/energy_consumption_finland.csv\"\n",
    "weather_file = f\"{DATA_DIR}/weather_finland_historical.csv\"\n",
    "\n",
    "df_processed.to_csv(energy_file, index=False)\n",
    "df_weather_processed.to_csv(weather_file, index=False)\n",
    "\n",
    "print(f\" Saved energy data to: {energy_file}\")\n",
    "print(f\"  - {len(df_processed)} records from {df_processed['date'].min()} to {df_processed['date'].max()}\")\n",
    "print(f\" Saved weather data to: {weather_file}\")\n",
    "print(f\"  - {len(df_weather_processed)} records from {df_weather_processed['date'].min()} to {df_weather_processed['date'].max()}\")\n",
    "print(f\"\\n All data saved successfully in: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b6897",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> STEP 8: Connect to Hopsworks Feature Store</span>\n",
    "\n",
    "Now we'll connect to Hopsworks and upload the processed data to feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec3a6285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Hopsworks Feature Store: id2223_10_featurestore\n"
     ]
    }
   ],
   "source": [
    "fs = project.get_feature_store() \n",
    "\n",
    "try:\n",
    "    secrets = project.get_secrets_api()\n",
    "except AttributeError:\n",
    "    try:\n",
    "        secrets = project.get_secret_store()\n",
    "    except AttributeError:\n",
    "        secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "print(f\"Connected to Hopsworks Feature Store: {fs.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385f729",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> STEP 9: Create Feature Groups and Upload Data </span>\n",
    "\n",
    "### <span style='color:#ff5f27'> Energy Consumption Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302a0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fg = fs.get_or_create_feature_group(\n",
    "    name=\"energy_consumption\",\n",
    "    version=1,\n",
    "    description=\"Historical electricity consumption data from Fingrid with temporal and lag features\",\n",
    "    primary_key=['country'],\n",
    "    event_time='date',\n",
    "    expectation_suite=energy_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e17f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286359/fs/1284182/fg/1880554\n",
      "2026-01-01 20:47:02,655 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286359/fs/1284182/fg/1880554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% || Rows 383044/383044 | Elapsed Time: 00:13 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: energy_consumption_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286359/jobs/named/energy_consumption_1_offline_fg_materialization/executions\n",
      "2026-01-01 20:47:31,523 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2026-01-01 20:47:34,729 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-01 20:49:54,822 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-01 20:50:06,807 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('energy_consumption_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"consumption_mw\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 20000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 801843\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 5685.8,\n",
       "         \"element_count\": 383044,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-01-01T07:47:02.000654Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"energy_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2026-01-01T20:47:02.654923+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"a4c66df3-e74a-11f0-8199-d4bb044603ac\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20260101T194702.654923Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_fg.insert(df_processed, write_options={\"wait_for_job\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2f774dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x21898aff410>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy_fg.update_feature_description(\"date\", \"Timestamp of measurement (3-hour intervals)\")\n",
    "energy_fg.update_feature_description(\"consumption_mw\", \"Electricity consumption in Finland (megawatts)\")\n",
    "energy_fg.update_feature_description(\"country\", \"Country where consumption was measured\")\n",
    "energy_fg.update_feature_description(\"year\", \"Year extracted from date\")\n",
    "energy_fg.update_feature_description(\"month\", \"Month of year (1-12)\")\n",
    "energy_fg.update_feature_description(\"day\", \"Day of month\")\n",
    "energy_fg.update_feature_description(\"hour\", \"Hour of day\")\n",
    "energy_fg.update_feature_description(\"day_of_week\", \"Day of week (0=Monday, 6=Sunday)\")\n",
    "energy_fg.update_feature_description(\"is_weekend\", \"1 if weekend, 0 if weekday\")\n",
    "energy_fg.update_feature_description(\"week_of_year\", \"Week number in the year\")\n",
    "energy_fg.update_feature_description(\"consumption_lag_1\", \"Consumption 3 hours ago\")\n",
    "energy_fg.update_feature_description(\"consumption_lag_2\", \"Consumption 6 hours ago\")\n",
    "energy_fg.update_feature_description(\"consumption_lag_8\", \"Consumption 24 hours ago\")\n",
    "energy_fg.update_feature_description(\"consumption_rolling_mean_24h\", \"24-hour rolling mean consumption\")\n",
    "energy_fg.update_feature_description(\"consumption_rolling_std_24h\", \"24-hour rolling standard deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac6d15",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Weather Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "56437240",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name=\"weather_finland\",\n",
    "    version=1,\n",
    "    description=\"Historical weather data from Open-Meteo for Finland (measured in Helsinki)\",\n",
    "    primary_key=['country'],\n",
    "    event_time='date',\n",
    "    expectation_suite=weather_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19add896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/1286359/fs/1284182/fg/1880556\n",
      "2026-01-01 20:50:19,972 INFO: \t3 expectation(s) included in expectation_suite.\n",
      "Validation failed.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1286359/fs/1284182/fg/1880556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% || Rows 5848/5848 | Elapsed Time: 00:02 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_finland_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1286359/jobs/named/weather_finland_1_offline_fg_materialization/executions\n",
      "2026-01-01 20:50:37,980 INFO: Waiting for execution to finish. Current state: INITIALIZING. Final status: UNDEFINED\n",
      "2026-01-01 20:50:41,157 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2026-01-01 20:52:25,936 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2026-01-01 20:52:26,099 INFO: Waiting for log aggregation to finish.\n",
      "2026-01-01 20:52:34,771 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_finland_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": false,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"temperature_2m\",\n",
       "           \"min_value\": -50.0,\n",
       "           \"max_value\": 50.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 801844\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": -25.46666666666667,\n",
       "         \"element_count\": 5848,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-01-01T07:50:19.000972Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 100.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 801846\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.7000000000000001,\n",
       "         \"element_count\": 5848,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-01-01T07:50:19.000972Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": false,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation\",\n",
       "           \"min_value\": 0.0,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 801845\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 5848,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2026-01-01T07:50:19.000972Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 3,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 1,\n",
       "     \"success_percent\": 66.66666666666666\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2026-01-01T20:50:19.972342+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"1a62867f-e74b-11f0-af75-d4bb044603ac\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20260101T195019.972342Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_fg.insert(df_weather_processed, write_options={\"wait_for_job\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "921eec92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hsfs.feature_group.FeatureGroup at 0x21895b7c150>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Timestamp of weather measurement\")\n",
    "weather_fg.update_feature_description(\"country\", \"Country where weather is measured\")\n",
    "weather_fg.update_feature_description(\"temperature_2m\", \"Temperature in Celsius at 2m height\")\n",
    "weather_fg.update_feature_description(\"precipitation\", \"Precipitation in mm (3-hour total)\")\n",
    "weather_fg.update_feature_description(\"cloud_cover\", \"Cloud cover percentage (0-100)\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m\", \"Wind speed at 10m above ground (km/h)\")\n",
    "weather_fg.update_feature_description(\"wind_speed_100m\", \"Wind speed at 100m above ground (km/h) - important for wind turbines\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m\", \"Wind direction in degrees\")\n",
    "weather_fg.update_feature_description(\"surface_pressure\", \"Surface atmospheric pressure in hPa\")\n",
    "weather_fg.update_feature_description(\"shortwave_radiation\", \"Solar radiation in W/m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af3e69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd395552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy Consumption Feature Group:\n",
      "  Name: energy_consumption\n",
      "  Version: 1\n",
      "  Features: ['date', 'consumption_mw', 'country', 'year', 'month', 'day', 'hour', 'day_of_week', 'is_weekend', 'week_of_year', 'consumption_lag_1', 'consumption_lag_2', 'consumption_lag_8', 'consumption_rolling_mean_24h', 'consumption_rolling_std_24h']\n",
      "\n",
      "Weather Feature Group:\n",
      "  Name: weather_finland\n",
      "  Version: 1\n",
      "  Features: ['date', 'temperature_2m', 'precipitation', 'cloud_cover', 'wind_speed_10m', 'wind_speed_100m', 'wind_direction_10m', 'surface_pressure', 'shortwave_radiation', 'country']\n",
      "\n",
      "Join keys:\n",
      "  Energy FG primary keys: ['country']\n",
      "  Weather FG primary keys: ['country']\n",
      "\n",
      " Both feature groups created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Verify feature groups exist and have data\n",
    "print(\"Energy Consumption Feature Group:\")\n",
    "print(f\"  Name: {energy_fg.name}\")\n",
    "print(f\"  Version: {energy_fg.version}\")\n",
    "print(f\"  Features: {[f.name for f in energy_fg.features]}\")\n",
    "\n",
    "print(\"\\nWeather Feature Group:\")\n",
    "print(f\"  Name: {weather_fg.name}\")\n",
    "print(f\"  Version: {weather_fg.version}\")\n",
    "print(f\"  Features: {[f.name for f in weather_fg.features]}\")\n",
    "\n",
    "# Check if both have 'country' as join key\n",
    "print(\"\\nJoin keys:\")\n",
    "print(f\"  Energy FG primary keys: {energy_fg.primary_key}\")\n",
    "print(f\"  Weather FG primary keys: {weather_fg.primary_key}\")\n",
    "print(\"\\n Both feature groups created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407dbbad",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> Verify Feature Groups Created </span>\n",
    "\n",
    "Let's verify both feature groups were created successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfs-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
