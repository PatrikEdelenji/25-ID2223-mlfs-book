{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"IPython\")\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/fingrid from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('fingrid',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "print(f\"Root dir: {root_dir}\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` \n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "    print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "\n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e51319b",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 01: Feature Backfill for Fingrid Energy Consumption Data</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77395dcc",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2488b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hopsworks\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define today's date\n",
    "today = datetime.today()\n",
    "\n",
    "# Get API keys from settings\n",
    "FINGRID_API_KEY = settings.FINGRID_KEY\n",
    "if FINGRID_API_KEY is None:\n",
    "    print(\"Warning: FINGRID_KEY not found in .env file. You'll need it to fetch energy data.\")\n",
    "else:\n",
    "    # Convert SecretStr to plain string for use with requests library\n",
    "    FINGRID_API_KEY = FINGRID_API_KEY.get_secret_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4e3ecc",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> STEP 1: Get your Fingrid API Token and Store it in .env file</span>\n",
    "\n",
    "You need to get your Fingrid API key from https://data.fingrid.fi/en/\n",
    "\n",
    "Once you have your API key, save it to the .env file in the root directory of your project:\n",
    "\n",
    " * mv .env.example .env\n",
    " * edit .env\n",
    "\n",
    "In the .env file, add or update:\n",
    "\n",
    "`FINGRID_KEY=\"put your Fingrid API KEY value in this string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "project = hopsworks.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fe50e9",
   "metadata": {},
   "source": [
    "## Hopsworks API Key\n",
    "\n",
    "You need to have registered an account on app.hopsworks.ai.\n",
    "\n",
    "Save the HOPSWORKS_API_KEY to the .env file in the root directory of your project:\n",
    "\n",
    " * mv .env.example .env\n",
    " * edit .env\n",
    "\n",
    "In the .env file, update HOPSWORKS_API_KEY:\n",
    "\n",
    "`HOPSWORKS_API_KEY=\"put API KEY value in this string\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12349995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FINGRID_BASE_URL = \"https://data.fingrid.fi/api/datasets\"\n",
    "DATASET_ID = \"193\"  # Electricity consumption in Finland (MW)\n",
    "\n",
    "# Weather location (Helsinki coordinates as representative measurement point for Finland)\n",
    "COUNTRY = \"Finland\"\n",
    "CITY = \"Helsinki\"\n",
    "LATITUDE = 60.1699\n",
    "LONGITUDE = 24.9384\n",
    "\n",
    "# Backfill configuration - how many days of historical data to download\n",
    "BACKFILL_DAYS = 730  # 2 years of data for complete seasonal coverage\n",
    "end_date = today\n",
    "start_date = end_date - timedelta(days=BACKFILL_DAYS)\n",
    "\n",
    "# Local storage configuration\n",
    "DATA_DIR = f\"{root_dir}/data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Country: {COUNTRY}\")\n",
    "print(f\"Weather measurement location: {CITY} ({LATITUDE}, {LONGITUDE})\")\n",
    "print(f\"Backfill period: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Local data directory: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e03e65",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 2: Download Historical Energy Consumption Data from Fingrid</span>\n",
    "\n",
    "We will fetch historical electricity consumption data from Fingrid's open data API.\n",
    "The data is measured every 3 hours and represents Finland's nationwide electricity consumption in megawatts (MW)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a5adf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_fingrid_data(dataset_id, start_date, end_date, api_key):\n",
    "    \"\"\"\n",
    "    Fetch historical data from Fingrid API.\n",
    "    \n",
    "    Args:\n",
    "        dataset_id: Fingrid dataset ID\n",
    "        start_date: Start date (datetime)\n",
    "        end_date: End date (datetime)\n",
    "        api_key: Fingrid API key\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with timestamp and value columns\n",
    "    \"\"\"\n",
    "    url = f\"{FINGRID_BASE_URL}/{dataset_id}/data\"\n",
    "    \n",
    "    params = {\n",
    "        \"startTime\": start_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        \"endTime\": end_date.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "        \"format\": \"json\",\n",
    "        \"pageSize\": 20000  # Max records per request\n",
    "    }\n",
    "    \n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"Accept\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching energy data from {params['startTime']} to {params['endTime']}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'data' in data:\n",
    "            df = pd.DataFrame(data['data'])\n",
    "            print(f\"Fetched {len(df)} records from Fingrid API\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Warning: No 'data' field in response: {list(data.keys())}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def fetch_weather_data(latitude, longitude, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Fetch historical weather data from Open-Meteo API.\n",
    "    Free API - no key required!\n",
    "    \n",
    "    Args:\n",
    "        latitude: Location latitude\n",
    "        longitude: Location longitude\n",
    "        start_date: Start date (datetime)\n",
    "        end_date: End date (datetime)\n",
    "    \n",
    "    Returns:\n",
    "        pandas DataFrame with weather variables\n",
    "    \"\"\"\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    \n",
    "    # Format dates for API\n",
    "    start_str = start_date.strftime(\"%Y-%m-%d\")\n",
    "    end_str = end_date.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Weather variables optimized for energy forecasting\n",
    "    params = {\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"start_date\": start_str,\n",
    "        \"end_date\": end_str,\n",
    "        \"hourly\": [\n",
    "            \"temperature_2m\",\n",
    "            \"precipitation\",\n",
    "            \"cloud_cover\",\n",
    "            \"wind_speed_10m\",\n",
    "            \"wind_speed_100m\",\n",
    "            \"wind_direction_10m\",\n",
    "            \"surface_pressure\",\n",
    "            \"shortwave_radiation\"\n",
    "        ],\n",
    "        \"timezone\": \"Europe/Helsinki\"\n",
    "    }\n",
    "    \n",
    "    print(f\"Fetching weather data from {start_str} to {end_str}...\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, params=params, timeout=30)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        if 'hourly' in data:\n",
    "            # Convert to DataFrame\n",
    "            hourly = data['hourly']\n",
    "            df = pd.DataFrame({\n",
    "                'date': pd.to_datetime(hourly['time']),\n",
    "                'temperature_2m': hourly['temperature_2m'],\n",
    "                'precipitation': hourly['precipitation'],\n",
    "                'cloud_cover': hourly['cloud_cover'],\n",
    "                'wind_speed_10m': hourly['wind_speed_10m'],\n",
    "                'wind_speed_100m': hourly['wind_speed_100m'],\n",
    "                'wind_direction_10m': hourly['wind_direction_10m'],\n",
    "                'surface_pressure': hourly['surface_pressure'],\n",
    "                'shortwave_radiation': hourly['shortwave_radiation']\n",
    "            })\n",
    "            \n",
    "            print(f\"Fetched {len(df)} hourly weather records\")\n",
    "            return df\n",
    "        else:\n",
    "            print(f\"Warning: No 'hourly' field in response: {list(data.keys())}\")\n",
    "            return pd.DataFrame()\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "print(\"Data fetching functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2541a0",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Fetch Energy Data from Fingrid API</span>\n",
    "\n",
    "We fetch data in chunks to respect API rate limits and avoid timeouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad7abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch data in chunks if needed (Fingrid API may have limits)\n",
    "all_data = []\n",
    "current_start = start_date\n",
    "chunk_days = 7  # Fetch 7 days at a time\n",
    "\n",
    "while current_start < end_date:\n",
    "    current_end = min(current_start + timedelta(days=chunk_days), end_date)\n",
    "    \n",
    "    df_chunk = fetch_fingrid_data(\n",
    "        dataset_id=DATASET_ID,\n",
    "        start_date=current_start,\n",
    "        end_date=current_end,\n",
    "        api_key=FINGRID_API_KEY\n",
    "    )\n",
    "    \n",
    "    if not df_chunk.empty:\n",
    "        all_data.append(df_chunk)\n",
    "    \n",
    "    current_start = current_end\n",
    "    \n",
    "    # Add delay to respect rate limits\n",
    "    if current_start < end_date:\n",
    "        time.sleep(2)\n",
    "\n",
    "# Combine all chunks\n",
    "if all_data:\n",
    "    df_raw = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\nTotal records fetched: {len(df_raw)}\")\n",
    "    df_raw.head()\n",
    "else:\n",
    "    raise ValueError(\"No data fetched. Check API key and date range.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cc48e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 3: Download Historical Weather Data </span>\n",
    "\n",
    "We download historical weather data for Helsinki (representative location for Finland) using the free Open-Meteo API.\n",
    "\n",
    "The weather features we download are optimized for energy forecasting:\n",
    " * `temperature` - impacts heating/cooling demand\n",
    " * `precipitation` - affects hydropower generation\n",
    " * `wind speed` - important for wind power generation\n",
    " * `solar radiation` - affects solar power generation\n",
    " * `cloud cover` - impacts solar generation\n",
    " * `surface pressure` - general weather indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f25efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch weather data\n",
    "df_weather_raw = fetch_weather_data(\n",
    "    latitude=LATITUDE,\n",
    "    longitude=LONGITUDE,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date\n",
    ")\n",
    "\n",
    "if not df_weather_raw.empty:\n",
    "    print(f\"\\nTotal weather records fetched: {len(df_weather_raw)}\")\n",
    "    print(f\"Date range: {df_weather_raw['date'].min()} to {df_weather_raw['date'].max()}\")\n",
    "    df_weather_raw.head()\n",
    "else:\n",
    "    raise ValueError(\"No weather data fetched. Check date range and network connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23da6c",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> STEP 4: Process Weather Data </span>\n",
    "\n",
    "We resample the hourly weather data to 3-hour intervals to match the frequency of the energy consumption data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafec824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_weather_data(df):\n",
    "    \"\"\"\n",
    "    Process weather data to match energy consumption frequency.\n",
    "    Resample hourly data to 3-hour intervals to match Fingrid data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Set date as index for resampling\n",
    "    df.set_index('date', inplace=True)\n",
    "    \n",
    "    # Resample to 3-hour intervals\n",
    "    df_resampled = df.resample('3H').agg({\n",
    "        'temperature_2m': 'mean',\n",
    "        'precipitation': 'sum',\n",
    "        'cloud_cover': 'mean',\n",
    "        'wind_speed_10m': 'mean',\n",
    "        'wind_speed_100m': 'mean',\n",
    "        'wind_direction_10m': 'mean',\n",
    "        'surface_pressure': 'mean',\n",
    "        'shortwave_radiation': 'mean'\n",
    "    })\n",
    "    \n",
    "    # Reset index to make date a column\n",
    "    df_resampled.reset_index(inplace=True)\n",
    "    \n",
    "    # Add country identifier\n",
    "    df_resampled['country'] = COUNTRY\n",
    "    \n",
    "    # Drop any NaN rows\n",
    "    df_resampled = df_resampled.dropna()\n",
    "    \n",
    "    return df_resampled\n",
    "\n",
    "# Process the weather data\n",
    "df_weather_processed = process_weather_data(df_weather_raw)\n",
    "\n",
    "print(f\"Weather data processed: {len(df_weather_processed)} records (3-hour intervals)\")\n",
    "df_weather_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c4a02",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 5: Process Energy Consumption Data </span>\n",
    "\n",
    "We process the raw energy data and add temporal features to help with forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65399117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_energy_data(df):\n",
    "    \"\"\"\n",
    "    Process and engineer features from raw Fingrid data.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Parse timestamp\n",
    "    timestamp_col = 'start_time' if 'start_time' in df.columns else 'startTime'\n",
    "    if timestamp_col not in df.columns:\n",
    "        timestamp_col = df.columns[0]\n",
    "    \n",
    "    df['date'] = pd.to_datetime(df[timestamp_col])\n",
    "    \n",
    "    # Get consumption value\n",
    "    value_col = 'value' if 'value' in df.columns else df.columns[1]\n",
    "    df['consumption_mw'] = pd.to_numeric(df[value_col], errors='coerce')\n",
    "    \n",
    "    # Remove duplicates and sort\n",
    "    df = df.drop_duplicates(subset=['date'])\n",
    "    df = df.sort_values('date')\n",
    "    \n",
    "    # Extract temporal features\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['hour'] = df['date'].dt.hour\n",
    "    df['day_of_week'] = df['date'].dt.dayofweek\n",
    "    df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
    "    df['week_of_year'] = df['date'].dt.isocalendar().week\n",
    "    \n",
    "    # Create lag features\n",
    "    df['consumption_lag_1'] = df['consumption_mw'].shift(1)\n",
    "    df['consumption_lag_2'] = df['consumption_mw'].shift(2)\n",
    "    df['consumption_lag_8'] = df['consumption_mw'].shift(8)\n",
    "    \n",
    "    # Rolling statistics\n",
    "    df['consumption_rolling_mean_24h'] = df['consumption_mw'].rolling(window=8, min_periods=1).mean()\n",
    "    df['consumption_rolling_std_24h'] = df['consumption_mw'].rolling(window=8, min_periods=1).std()\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    df = df.dropna(subset=['date', 'consumption_mw'])\n",
    "    \n",
    "    # Add country identifier\n",
    "    df['country'] = COUNTRY\n",
    "    \n",
    "    # Select final columns\n",
    "    feature_columns = [\n",
    "        'date',\n",
    "        'consumption_mw',\n",
    "        'country',\n",
    "        'year',\n",
    "        'month',\n",
    "        'day',\n",
    "        'hour',\n",
    "        'day_of_week',\n",
    "        'is_weekend',\n",
    "        'week_of_year',\n",
    "        'consumption_lag_1',\n",
    "        'consumption_lag_2',\n",
    "        'consumption_lag_8',\n",
    "        'consumption_rolling_mean_24h',\n",
    "        'consumption_rolling_std_24h'\n",
    "    ]\n",
    "    \n",
    "    df = df[feature_columns]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_processed = process_energy_data(df_raw)\n",
    "\n",
    "print(f\"Data processed: {len(df_processed)} records\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9cf50bc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 6: Define Data Validation Rules </span>\n",
    "\n",
    "We define data validation rules (expectations) to ensure data quality before writing to Hopsworks.\n",
    "This prevents garbage-in, garbage-out scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de466bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import great_expectations as ge\n",
    "\n",
    "energy_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"energy_expectation_suite\"\n",
    ")\n",
    "\n",
    "energy_expectation_suite.add_expectation(\n",
    "    ge.core.ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_min_to_be_between\",\n",
    "        kwargs={\n",
    "            \"column\": \"consumption_mw\",\n",
    "            \"min_value\": 0.0,\n",
    "            \"max_value\": 20000.0,\n",
    "            \"strict_min\": True\n",
    "        }\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524498d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_expectation_suite = ge.core.ExpectationSuite(\n",
    "    expectation_suite_name=\"weather_expectation_suite\"\n",
    ")\n",
    "\n",
    "def expect_reasonable_weather(col, min_val, max_val):\n",
    "    weather_expectation_suite.add_expectation(\n",
    "        ge.core.ExpectationConfiguration(\n",
    "            expectation_type=\"expect_column_min_to_be_between\",\n",
    "            kwargs={\n",
    "                \"column\": col,\n",
    "                \"min_value\": min_val,\n",
    "                \"max_value\": max_val,\n",
    "                \"strict_min\": True\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "expect_reasonable_weather(\"temperature_2m\", -50.0, 50.0)\n",
    "expect_reasonable_weather(\"precipitation\", 0.0, 500.0)\n",
    "expect_reasonable_weather(\"wind_speed_10m\", 0.0, 100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71f036a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style='color:#ff5f27'> STEP 7: Save Processed Data Locally </span>\n",
    "\n",
    "Before uploading to Hopsworks, save the processed dataframes as CSV files in the data directory for backup and offline analysis.\n",
    "\n",
    "The files will be saved as:\n",
    " * `energy_consumption_finland.csv` - Energy consumption with features (2 years)\n",
    " * `weather_finland_historical.csv` - Historical weather data (2 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828e718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data to CSV files in the data directory\n",
    "# Using unique names to avoid conflicts with other project data\n",
    "energy_file = f\"{DATA_DIR}/energy_consumption_finland.csv\"\n",
    "weather_file = f\"{DATA_DIR}/weather_finland_historical.csv\"\n",
    "\n",
    "df_processed.to_csv(energy_file, index=False)\n",
    "df_weather_processed.to_csv(weather_file, index=False)\n",
    "\n",
    "print(f\"✓ Saved energy data to: {energy_file}\")\n",
    "print(f\"  - {len(df_processed)} records from {df_processed['date'].min()} to {df_processed['date'].max()}\")\n",
    "print(f\"✓ Saved weather data to: {weather_file}\")\n",
    "print(f\"  - {len(df_weather_processed)} records from {df_weather_processed['date'].min()} to {df_weather_processed['date'].max()}\")\n",
    "print(f\"\\n✓ All data saved successfully in: {DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01b6897",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## <span style=\"color:#ff5f27;\"> STEP 8: Connect to Hopsworks Feature Store</span>\n",
    "\n",
    "Now we'll connect to Hopsworks and upload the processed data to feature groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3a6285",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = project.get_feature_store() \n",
    "\n",
    "try:\n",
    "    secrets = project.get_secrets_api()\n",
    "except AttributeError:\n",
    "    try:\n",
    "        secrets = project.get_secret_store()\n",
    "    except AttributeError:\n",
    "        secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "print(f\"Connected to Hopsworks Feature Store: {fs.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0385f729",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> STEP 9: Create Feature Groups and Upload Data </span>\n",
    "\n",
    "### <span style='color:#ff5f27'> Energy Consumption Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302a0e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fg = fs.get_or_create_feature_group(\n",
    "    name=\"energy_consumption\",\n",
    "    version=1,\n",
    "    description=\"Historical electricity consumption data from Fingrid with temporal and lag features\",\n",
    "    primary_key=['country'],\n",
    "    event_time='date',\n",
    "    expectation_suite=energy_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e17f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fg.insert(df_processed, write_options={\"wait_for_job\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f774dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_fg.update_feature_description(\"date\", \"Timestamp of measurement (3-hour intervals)\")\n",
    "energy_fg.update_feature_description(\"consumption_mw\", \"Electricity consumption in Finland (megawatts)\")\n",
    "energy_fg.update_feature_description(\"country\", \"Country where consumption was measured\")\n",
    "energy_fg.update_feature_description(\"year\", \"Year extracted from date\")\n",
    "energy_fg.update_feature_description(\"month\", \"Month of year (1-12)\")\n",
    "energy_fg.update_feature_description(\"day\", \"Day of month\")\n",
    "energy_fg.update_feature_description(\"hour\", \"Hour of day\")\n",
    "energy_fg.update_feature_description(\"day_of_week\", \"Day of week (0=Monday, 6=Sunday)\")\n",
    "energy_fg.update_feature_description(\"is_weekend\", \"1 if weekend, 0 if weekday\")\n",
    "energy_fg.update_feature_description(\"week_of_year\", \"Week number in the year\")\n",
    "energy_fg.update_feature_description(\"consumption_lag_1\", \"Consumption 3 hours ago\")\n",
    "energy_fg.update_feature_description(\"consumption_lag_2\", \"Consumption 6 hours ago\")\n",
    "energy_fg.update_feature_description(\"consumption_lag_8\", \"Consumption 24 hours ago\")\n",
    "energy_fg.update_feature_description(\"consumption_rolling_mean_24h\", \"24-hour rolling mean consumption\")\n",
    "energy_fg.update_feature_description(\"consumption_rolling_std_24h\", \"24-hour rolling standard deviation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac6d15",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> Weather Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56437240",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg = fs.get_or_create_feature_group(\n",
    "    name=\"weather_finland\",\n",
    "    version=1,\n",
    "    description=\"Historical weather data from Open-Meteo for Finland (measured in Helsinki)\",\n",
    "    primary_key=['country'],\n",
    "    event_time='date',\n",
    "    expectation_suite=weather_expectation_suite\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19add896",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg.insert(df_weather_processed, write_options={\"wait_for_job\": True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921eec92",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_fg.update_feature_description(\"date\", \"Timestamp of weather measurement\")\n",
    "weather_fg.update_feature_description(\"country\", \"Country where weather is measured\")\n",
    "weather_fg.update_feature_description(\"temperature_2m\", \"Temperature in Celsius at 2m height\")\n",
    "weather_fg.update_feature_description(\"precipitation\", \"Precipitation in mm (3-hour total)\")\n",
    "weather_fg.update_feature_description(\"cloud_cover\", \"Cloud cover percentage (0-100)\")\n",
    "weather_fg.update_feature_description(\"wind_speed_10m\", \"Wind speed at 10m above ground (km/h)\")\n",
    "weather_fg.update_feature_description(\"wind_speed_100m\", \"Wind speed at 100m above ground (km/h) - important for wind turbines\")\n",
    "weather_fg.update_feature_description(\"wind_direction_10m\", \"Wind direction in degrees\")\n",
    "weather_fg.update_feature_description(\"surface_pressure\", \"Surface atmospheric pressure in hPa\")\n",
    "weather_fg.update_feature_description(\"shortwave_radiation\", \"Solar radiation in W/m²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af3e69",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd395552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify feature groups exist and have data\n",
    "print(\"Energy Consumption Feature Group:\")\n",
    "print(f\"  Name: {energy_fg.name}\")\n",
    "print(f\"  Version: {energy_fg.version}\")\n",
    "print(f\"  Features: {[f.name for f in energy_fg.features]}\")\n",
    "\n",
    "print(\"\\nWeather Feature Group:\")\n",
    "print(f\"  Name: {weather_fg.name}\")\n",
    "print(f\"  Version: {weather_fg.version}\")\n",
    "print(f\"  Features: {[f.name for f in weather_fg.features]}\")\n",
    "\n",
    "# Check if both have 'country' as join key\n",
    "print(\"\\nJoin keys:\")\n",
    "print(f\"  Energy FG primary keys: {energy_fg.primary_key}\")\n",
    "print(f\"  Weather FG primary keys: {weather_fg.primary_key}\")\n",
    "print(\"\\n✓ Both feature groups created successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlfs-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
